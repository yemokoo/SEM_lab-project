# -*- coding: utf-8 -*-
import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, input_file_name, regexp_extract, count, avg
from pyspark.sql.types import StructType, StructField, IntegerType

def calculate_daily_activity_probability_from_csv():
    """
    1ë…„ê°„ì˜ Raw CSV ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° ì°¨ëŸ‰(OBU_ID)ì´ í•˜ë£¨ì— ìš´í–‰í•  í‰ê·  í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    ë¡œì§:
    1. ì§€ì •ëœ ê²½ë¡œì˜ ëª¨ë“  CSV íŒŒì¼(..._YYYYMMDD.csv)ì„ í•œ ë²ˆì— ì½ì–´ë“¤ì…ë‹ˆë‹¤.
    2. íŒŒì¼ ì´ë¦„ì—ì„œ ë‚ ì§œ ì •ë³´(YYYYMMDD)ë¥¼ ì¶”ì¶œí•˜ì—¬ 'date' ì»¬ëŸ¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    3. ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ì´ ê³ ìœ  ë‚ ì§œ ìˆ˜(ì „ì²´ ìš´í–‰ì¼ìˆ˜)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    4. ê° OBU_IDë³„ë¡œ ê³ ìœ í•œ ìš´í–‰ì¼ìˆ˜ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤.
    5. (OBU_IDë³„ ìš´í–‰ì¼ìˆ˜ / ì´ ìš´í–‰ì¼ìˆ˜) ë¥¼ í†µí•´ OBU_IDë³„ 'ì¼ì¼ ìš´í–‰ í™•ë¥ 'ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    6. ëª¨ë“  OBU_IDì˜ 'ì¼ì¼ ìš´í–‰ í™•ë¥ 'ì˜ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
    """
    spark = (
        SparkSession.builder.appName("CalculateOBUActivityProbabilityFromCSV")
        .config("spark.driver.memory", "8g")
        .getOrCreate()
    )

    raw_data_base_path = r"D:/ì—°êµ¬ì‹¤/ì—°êµ¬/í™”ë¬¼ì°¨ ì¶©ì „ì†Œ ë°°ì¹˜ ìµœì í™”/Data/Raw_Data/Trajectory"
    
    # ë¶„ì„ì— OBU_IDë§Œ í•„ìš”í•˜ë¯€ë¡œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ ìµœì†Œí•œì˜ ìŠ¤í‚¤ë§ˆë§Œ ì •ì˜
    minimal_schema = StructType([
        StructField("OBU_ID", IntegerType(), True)
    ])
    
    try:
        # Windows ë¡œì»¬ ê²½ë¡œì—ì„œ ì™€ì¼ë“œì¹´ë“œ(*) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ file:/// ìŠ¤í‚¤ë§ˆë¥¼ ëª…ì‹œ
        load_path = f"file:///{raw_data_base_path}/*.csv"
        
        df = spark.read.csv(
            load_path,
            header=True,
            schema=minimal_schema
        ).na.drop(subset=["OBU_ID"])

        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ(YYYYMMDD)ë¥¼ ì¶”ì¶œí•˜ì—¬ 'date' ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
        # ì˜ˆ: '.../AUTO_P1_TRUCK_SERO_20200101.csv' -> '20200101'
        df_with_date = df.withColumn("date", regexp_extract(input_file_name(), r'_(\d{8})\.csv', 1))
        
        distinct_obu_date = df_with_date.select("OBU_ID", "date").distinct()
        distinct_obu_date.cache()
        
        total_unique_days = distinct_obu_date.select("date").distinct().count()
        if total_unique_days == 0:
            print("ì˜¤ë¥˜: ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë‚˜ íŒŒì¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return

        active_days_per_obu = distinct_obu_date.groupBy("OBU_ID").agg(
            count("date").alias("active_days")
        )

        obu_probabilities_df = active_days_per_obu.withColumn(
            "activity_probability", col("active_days") / total_unique_days
        )
        
        print("\n[ìƒ˜í”Œ] OBU_IDë³„ ìš´í–‰ì¼ìˆ˜ ë° ìš´í–‰ í™•ë¥ :")
        obu_probabilities_df.show(5)

        final_avg_probability_row = obu_probabilities_df.agg(
            avg("activity_probability").alias("avg_probability")
        ).first()
        final_avg_probability = final_avg_probability_row['avg_probability'] if final_avg_probability_row else 0
        
        print("\n--- ìµœì¢… ê²°ê³¼ ìš”ì•½ ---")
        print(f"ë¶„ì„ ëŒ€ìƒ ì´ ê³ ìœ  OBU_ID ìˆ˜: {obu_probabilities_df.count()}")
        print(f"ë¶„ì„ ê¸°ê°„(ê³ ìœ  ì¼ìˆ˜): {total_unique_days}ì¼")
        print(f"ğŸ“Š ì°¨ëŸ‰ ë‹¹ í‰ê·  ì¼ì¼ ìš´í–‰ í™•ë¥ : {final_avg_probability:.4f} ({final_avg_probability:.2%})")

        output_dir = r"D:/ì—°êµ¬ì‹¤/ì—°êµ¬/í™”ë¬¼ì°¨ ì¶©ì „ì†Œ ë°°ì¹˜ ìµœì í™”/Code/SEM_lab-project/resource_data/obu_activity_analysis"
        file_name = "obu_daily_activity_probability_from_raw.csv"
        full_path = f"{output_dir}/{file_name}"
        
        os.makedirs(output_dir, exist_ok=True)
        
        pandas_df_results = obu_probabilities_df.toPandas()
        pandas_df_results.to_csv(full_path, index=False, encoding='utf-8-sig')
        print(f"\nOBU_IDë³„ ìƒì„¸ ê²°ê³¼ê°€ ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\n{full_path}")

    except Exception as e:
        print(f"\nìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    finally:
        spark.stop()
        print("\nâ¹ï¸ SparkSession ì¢…ë£Œë¨.")

if __name__ == "__main__":
    calculate_daily_activity_probability_from_csv()
